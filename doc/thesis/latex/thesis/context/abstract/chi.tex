% ------------------------------------------------
\StartAbstractChi
% ------------------------------------------------
在對話生成中，高自然度的回應對有效的人機互動至關重要，這些回應能顯著提升使用者對於對話系統的互動體驗。在進行個人化對話生成時，要達成此目標更加的困難，因為回應需要既流暢且連貫，又要與使用者的個人特質或角色描述保持一致。在本研究中我們提出了一種名為 \textbf{MUDI}（\textbf{Mu}ltiple \textbf{Di}sourse Relations Graph Learning）的新方法，旨在有效建模與整合個人化對話生成中對話上下文的語篇關係與角色資訊。首先，為了讓模型學習對話中的語篇連貫關係，我們透過大型語言模型協助標註對話資料中的語篇關係，並受到先前研究的啟發，我們將對話資料轉為對話圖的形式，接著透過提出的對話增強圖神經網路 DialogueGAT，作為編碼器來捕捉對話結構內隱含的語篇連貫關係。另外我們將角色描述也透過圖編碼器轉變為全連接的角色圖形式，以捕捉角色句子間的語意關係。最後我們藉由基於注意力機制的特徵融合方式將來自對話圖與角色圖的資訊進行融合，以產生個人化的語篇增強對話表示。此外我們同時透過文字編碼器在語意與段落層面捕捉對話上下文與角色描述的隱含關係。而在生成個人化回應的階段，我們首先採用基於提示的條件對話生成機制，通過精心設計的提示來引導生成個性化回應的過程，以及引入了連貫性增強的注意力機制，結合可學習嵌入和文字表示以增強解碼器在預測下一個詞語時考量語篇關係的能力，使其在生成文字的過程中能多加考慮那些隱含連貫性資訊的詞彙。實驗結果與實際案例探討表明，我們提出的方法 \textbf{MUDI} 顯著改善了個人化對話生成的回應品質，有效整合語篇關係與角色資訊，使生成回應更加連貫與遵循角色設定，並且更加自然，能產生更像人類的對話回應。

% ------------------------------------------------
\EndAbstractChi
% ------------------------------------------------
