% ------------------------------------------------
\StartChapter{Introduction}{chapter:introduction}
% ------------------------------------------------

\section{Personalized Dialogue Generation}
Dialogue Generation is a foundational technology for dialogue systems, primarily focusing on the task of Next Utterance Generation, also known as Next Response Generation. In multi-turn dialogue scenarios, the conversational agent's objective is to analyze the context of the multi-turn dialogue and the current query to produce a following appropriate response. A significant drawback of traditional dialogue systems is their limited ability to personalize responses based on specific user characteristics or preferences. This limitation often results in generic and less engaging interactions that fail to meet individual user needs effectively \cite{jiang-de-rijke-2018-sequence}. Previous works \cite{song-etal-2020-generating} \cite{warren-2006-features} defined this problem as the naturalness issue of the Dialogue System.

One effective solution to enhance the naturalness of dialogue systems is to integrate personality into the agents, referred to as "persona". Typically, a persona comprises several sentences describing the interlocutor's facts or background. This information is crucial for building a trustworthy and confident dialogue system. By endowing chatbot agents with human-like traits, the interactions become more realistic. Given these benefits, Personalized Dialogue Generation has emerged as a hot research topic in recent years, focusing on improving user engagement and satisfaction in dialogue systems. For a visual representation of the differences between general and personalized dialogue generation, refer to Figure \ref{fig:intro_dg_vs_pdg} below. This illustration provides clear examples of how responses vary depending on whether or not the system incorporates personalized information.

Personalized dialogue generation aims for conversational agents to produce responses that are not only factually accurate but also tailored and coherent based on the persona and dialogue history. The task involves developing a dialogue model that generates responses for one interlocutor based on the assigned personas of two interlocutors, with consideration for the dialogue history between them. The generated response should exhibit consistency with the dialogue history and persona backgrounds while reflecting the self-persona expression and engagement with the counterpart. In summary, by incorporating personalized information into dialogue systems, we can create interactions that are not only more engaging and realistic but also more reflective of actual human conversations. This approach not only improves the user experience by providing tailored and coherent responses but also contributes significantly to the advancement of personalized applications such as personal assistants in current technology landscapes.

\InsertFigure
[scale=0.12,
caption={Comparison of General vs. Personalized Dialogue Generation. On top of that, we see an example of a general dialogue system, which produces a generic response that could apply to any user without consideration for individual characteristics. On the bottom, the personalized dialogue system generates a response that considers specific details from the user's persona (red font).},
label={fig:intro_dg_vs_pdg}
]
{./context/introduction/images/intro_dg_vs_pdg.png}

\section{Motivation}
In recent years, there has been a surge of interest in personalized dialogue generation methods, spurred mainly by the release of publicly available large-scale datasets such as those introduced by Zhang et al. \cite{zhang-etal-2018-personalizing} and Dinan et al. \cite{dinan-etal-2019-convai2}. These datasets have significantly advanced efforts to enhance persona consistency and context understanding between generated responses and dialogue. For example, Liu et al. \cite{liu-etal-2020-impress} have concentrated on improving dialogue system consistency through more sophisticated modeling of interlocutor understanding. Song et al. \cite{song-etal-2021-bob} tackled persona-based dialogue generation by dividing it into two separate tasks: response generation and consistency understanding. They utilized unlikelihood training techniques to reduce the production of contradictory dialogue responses. Furthermore, Bao et al. \cite{bao-etal-2020-plato} \cite{bao-etal-2021-plato} employed latent variables to model response intentions and applied a response selection task to ensure that the generated responses align with both the dialogue context and background knowledge, such as persona information. Additionally, Huang et al. \cite{huang-etal-2023-paa} proposed a persona-adaptive attention that balances and regularizes the input information from persona and context, improving the consistent understanding of generated responses by persona and context.

Despite these advances, significant challenges persist in enhancing engagement, response coherence, and persona consistency in dialogue systems. These challenges are primarily twofold. Firstly, many existing methods rely on sophisticated structures or external natural language inference (NLI) datasets to learn persona consistency. This approach, while effective, can sometimes lead the model to overly prioritize persona information at the expense of neglecting the broader dialogue context. Secondly, many dialogue-generating models fail to adequately consider the importance of discourse relations. They often neglect coherence, assuming that fluency alone can measure a dialogue's coherence. Discourse coherence, which focuses on how utterances are interconnected and the overall organization of dialogue to effectively convey information, is essential for effective conversation. Discourse coherence can be divided into local and global coherence. Local coherence refers to the logical connections between adjacent sentences, ensuring that they relate to each other and form a coherent sequence. Global coherence, on the other hand, extends beyond immediate sentence pairs to encompass higher-level relationships across the entire dialogue. This macro-linguistic capability allows conversational agents to maintain topic consistency and effectively convey meaning throughout an interaction. Poor global coherence can significantly impair the user's understanding of the discourse as a cohesive whole. As illustrated in Figure \ref{fig:intro_pdg}, the dialogue demonstrates various common issues encountered in personalized dialogue systems, including local and global incoherence as well as persona inconsistency. For example, consider the response "Speaking of tacos, we just got a new taco sauce in store!" This might seem appropriate and consistent with the persona in response to a query. However, this response could be incoherent within the broader context of the conversation. Additionally, the response "Ha ha, that's interesting! Do you drive? I drive a Nissan Pathfinder." is coherent with the query, but it introduces a strong and abrupt topic transition from the dialogue history. Furthermore, the remark "I get it. I actually don't like country music, which is what she used to sing." is not consistent with the persona, although it follows the conversation topic.

\InsertFigure
[scale=0.098,
caption={Example of Incoherence and Persona Inconsistency issue in Personalized Dialogue Generation. This figure highlights the challenges in maintaining coherence and persona consistency in dialogue generation. It illustrates instances of local incoherence, where adjacent sentences fail to logically connect; global incoherence, where the overall dialogue lacks cohesion; and persona inconsistency, where the chatbot's responses do not align with its defined persona attributes. Each type of error is marked to show how it disrupts the flow and authenticity of the conversation.
},
label={fig:intro_pdg}
]
{./context/introduction/images/intro_pdg.png}

In personalized dialogue generation, ensuring that the generated responses are consistent with the persona and coherent with the context of the dialogue is challenging. This is largely because inherent trade-offs exist between maintaining persona consistency and achieving discourse coherence. Moreover, few studies have successfully addressed the challenge of maintaining persona consistency while ensuring the generated responses' coherence. To address these challenges, this study introduces a novel approach utilizing graph learning to retain both local and global coherence information in dialogues. Additionally, We leverage prompt learning and attention mechanisms to use discourse relations as signals for conditional response generation. Our proposed approach could guide the model to generate responses that are both coherent with the context and consistent with the persona, effectively enhancing the naturalness of the personalized dialogue generation.

Our contributions are summarized as follows:
\begin{itemize}
    \item We introduce the novel framework \textbf{MUDI} (Multiple Discourse Relations Graph Learning), which enhances the naturalness of Personalized Dialogue Generation. To the best of our knowledge, \textbf{MUDI} is the first framework to jointly integrate Discourse Relations and Persona in Personalized Dialogue Generation.
    
    \item We utilize Prompt Learning and propose a Coherence-aware Attention mechanism to integrate discourse information, thereby guiding the conditional response generation process.

    \item We leverage Dynamic Weighting Aggregation to balance the discourse and persona information. 
    
    \item Through extensive experiments and a case study on the ConvAI2 dataset, our model demonstrates performance that is comparable to, or even surpasses, established baselines. Our approach enables the generation of responses that are more natural, enhancing the overall personalized conversational quality.
\end{itemize}

% ------------------------------------------------
\EndChapter
% ------------------------------------------------
